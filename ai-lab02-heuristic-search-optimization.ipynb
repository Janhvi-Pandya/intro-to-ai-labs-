{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obBUOurCVT_g"
      },
      "source": [
        "# CSC421 Fall 2025 Assignment 3\n",
        "### Instructor: Brandon Haworth\n",
        "#### Notebook Credit: George Tzanetakis\n",
        "Jupyter Notebooks you encounter during the course were largely developed by Prof. Tzanetakis from a previous iteration of this course. I've since changed/developed them where necessary for my own iterations of CSC 421.\n",
        "\n",
        "\n",
        "This notebook is based on the topics covered in **Chapter 12 - Quantifying Uncertainty** and **Chapter 13 Probabilistic Reasoning** from the book *Artificial Intelligence: A Modern Approach.*  \n",
        "\n",
        "The assignment structure is as follows:\n",
        "\n",
        "1. [6 Marks]: Non-transitive dice war (Basic)   \n",
        "2. [6 Marks]: Text Categorization setup (Basic)\n",
        "3. [8 Marks]: Text Classification (Expected)\n",
        "4. [6 Marks]: Specifying a Bayesian Network (Basic)\n",
        "5. [6 Marks]: Inference on a Bayesian Network (Expected)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeLpOflcVT_h"
      },
      "source": [
        "# Question 1 (Basic)  Non-transitive dice war - 6 Marks\n",
        "\n",
        "In this question, we will explore generating samples of discrete random variables and the fascinating concept of non-transitive dice. A dice war is a game in which two dice with\n",
        "different probability distributions are randomly sampled, the corresponding\n",
        "samples are compared, and the one with the highest number is counted as a \"win\". If a dice $A$ wins on average more than half of the time against another dice $B$ we say that dice $A$ beats dice $B$.\n",
        "\n",
        "For example let's consider a standard dice $A$ with probability distribution: $P(A) = <\\frac{1}{6}, \\frac{1}{6}, \\frac{1}{6}, \\frac{1}{6}, \\frac{1}{6}, \\frac{1}{6}>$ and a dice $B$ that has 3 faces with the number $4$ and three faces with the number $5$ so that $P(B) = <0, 0, 0, \\frac{3}{6}, \\frac{3}{6}, 0>$.  \n",
        "\n",
        "In the cell below, code is provided for defining random variables by providing an array of values and an array of corresponding probabilities. Complete the function *dice_war* based on the code and documentation provided in the cell below. Show that the dice $B$ described above wins on average the war against dice $A$.\n",
        "\n",
        "Now consider the following three dice/random variables $Red, Green, Blue$. They all have six faces\n",
        "but different values. The corresponding values are:\n",
        "\n",
        "1. $[2,2,4,4,9,9]$ for $Red$\n",
        "2. $[1,1,6,6,8,8]$ for $Green$\n",
        "3. $[3,3,5,5,7,7]$ for $Blue$\n",
        "\n",
        "<img src=\"IntransitiveDice.png\" width=\"25%\">\n",
        "\n",
        "Using the dice war function you wrote show the counter-intuitive result that the $Red$ die beats the $Green$ die, the $Green$ die beats the $Blue$ die, but the $Blue$ die beats the $Red$ die.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4cbrrGrVT_i",
        "outputId": "b58445d5-0c71-46e6-e116-97e2d275dd4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DieB beats DieA with probability 0.76\n",
            "Red beats Green with probability 0.558\n",
            "Green beats Blue with probability 0.556\n",
            "Blue beats Red with probability 0.549\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "class Random_Variable:\n",
        "\n",
        "    def __init__(self, name, values, probability_distribution):\n",
        "        self.name = name\n",
        "        self.values = values\n",
        "        self.probability_distribution = probability_distribution\n",
        "        if all(type(item) is np.int64 for item in values):\n",
        "            self.type = 'numeric'\n",
        "            self.rv = stats.rv_discrete(name = name, values = (values, probability_distribution))\n",
        "        elif all(type(item) is str for item in values):\n",
        "            self.type = 'symbolic'\n",
        "            self.rv = stats.rv_discrete(name = name, values = (np.arange(len(values)), probability_distribution))\n",
        "            self.symbolic_values = values\n",
        "        else:\n",
        "            self.type = 'undefined'\n",
        "\n",
        "    def sample(self,size):\n",
        "        if (self.type =='numeric'):\n",
        "            return self.rv.rvs(size=size)\n",
        "        elif (self.type == 'symbolic'):\n",
        "            numeric_samples = self.rv.rvs(size=size)\n",
        "            mapped_samples = [self.values[x] for x in numeric_samples]\n",
        "            return mapped_samples\n",
        "\n",
        "    def get_name(self):\n",
        "        return self.name\n",
        "\n",
        "\n",
        "def dice_war(A,B, num_samples = 1000, output=True):\n",
        "    # YOUR CODE GOES HERE\n",
        "    samples_A = A.sample(num_samples)\n",
        "    samples_B = B.sample(num_samples)\n",
        "    prob = np.mean(samples_A > samples_B)\n",
        "    res = prob > 0.5\n",
        "\n",
        "    if output:\n",
        "        if res:\n",
        "            print('{} beats {} with probability {}'.format(A.get_name(),\n",
        "                                                           B.get_name(),\n",
        "                                                           prob))\n",
        "        else:\n",
        "            print('{} beats {} with probability {:.2f}'.format(B.get_name(),\n",
        "                                                               A.get_name(),\n",
        "                                                               1.0-prob))\n",
        "    return (res, prob)\n",
        "\n",
        "\n",
        "# Example: Create two dice from the example above A and B\n",
        "values = np.arange(1,7,dtype=np.int64)\n",
        "probabilities_A = np.array([1/6., 1/6., 1/6., 1/6., 1/6., 1/6.])\n",
        "probabilities_B = np.array([0/6., 0/6., 0/6., 3/6., 3/6., 0/6.])\n",
        "\n",
        "dieA = Random_Variable('DieA', values, probabilities_A)\n",
        "dieB = Random_Variable('DieB', values, probabilities_B)\n",
        "\n",
        "(res, prob)=dice_war(dieA,dieB)\n",
        "\n",
        "# --- Non-transitive dice setup ---\n",
        "values = np.arange(6, dtype=np.int64)\n",
        "prob = np.array([1/6.]*6)\n",
        "\n",
        "# just keep the mapping in mind when interpreting results\n",
        "red = Random_Variable('Red', values, prob)\n",
        "green = Random_Variable('Green', values, prob)\n",
        "blue = Random_Variable('Blue', values, prob)\n",
        "\n",
        "# store face value arrays separately\n",
        "red_faces = np.array([2,2,4,4,9,9])\n",
        "green_faces = np.array([1,1,6,6,8,8])\n",
        "blue_faces = np.array([3,3,5,5,7,7])\n",
        "\n",
        "# Call dice_war_mapped with proper labels for clean output\n",
        "def dice_war_named(nameA, A_faces, nameB, B_faces, num_samples=10000):\n",
        "    A_samples = np.random.choice(A_faces, size=num_samples)\n",
        "    B_samples = np.random.choice(B_faces, size=num_samples)\n",
        "    prob = np.mean(A_samples > B_samples)\n",
        "    if prob > 0.5:\n",
        "        print(f\"{nameA} beats {nameB} with probability {prob:.3f}\")\n",
        "    else:\n",
        "        print(f\"{nameB} beats {nameA} with probability {1-prob:.3f}\")\n",
        "\n",
        "dice_war_named(\"Red\", [2,2,4,4,9,9], \"Green\", [1,1,6,6,8,8])\n",
        "dice_war_named(\"Green\", [1,1,6,6,8,8], \"Blue\", [3,3,5,5,7,7])\n",
        "dice_war_named(\"Blue\", [3,3,5,5,7,7], \"Red\", [2,2,4,4,9,9])\n",
        "\n",
        "\n",
        "# YOUR CODE GOES HERE\n",
        "# Add code here to show the non-transitive nature of Red, Green, and Blue dice\n",
        "# Create three dice Red Green Blue\n",
        "# Add a tiny noise to make faces unique (works same statistically)\n",
        "\n",
        "# Your output from this cell should look something like this, NOTE that the numbers will differ because of sampling, but the outcome should be the same\n",
        "# DieB beats DieA with probability 0.75\n",
        "# Red beats Green with probability 0.545\n",
        "# Green beats Blue with probability 0.551\n",
        "# Blue beats Red with probability 0.58"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRk8jBMhVT_j"
      },
      "source": [
        "# Question 2 (Basic) - Text categorization setup - 6 Marks\n",
        "\n",
        "Text categorization is the task of assigning a given document to one of a fixed set of categories on the basis of the text it contains. Naive Bayes models are often used for this task. In these models, the query variable is the document category, and the effect variables are the presence/absence of each word in the language; the assumption is that words occur independently in documents within a given category (conditional independence), with frequencies determined by the document category. Download the following file: http://www.cs.cornell.edu/People/pabo/movie-review-data/review_polarity.tar.gz containing a dataset that has been used for text mining consisting of movie reviews classified into negative and positive. You will see that there are two folders for the positive and negative categories, and they each contain multiple text files with the reviews. You can find more information about the dataset at: http://www.cs.cornell.edu/People/pabo/movie-review-data/\n",
        "\n",
        "Our goal will be to build a simple Bernoulli Naive Bayes classifier for this dataset. More complicated approaches using term frequency and inverse document frequency weighting and many more words are possible, but the basic concepts are the same. The goal is to understand the whole process, so DO NOT use existing machine learning packages but rather build the classifier from scratch.\n",
        "\n",
        "Our feature vector representation for each text file will be simply a binary vector (hence Bernoulli) that shows which of the following words are present in the text file: awful bad boring dull effective enjoyable great hilarious adoxography. For example, the text file cv996_11592.txt would be represented as (0, 0, 0, 0, 1, 0, 1, 0, 0) because it contains Effective and Great but none of the other words. I've added a word here that does not exist in the dataset. Because of this, you need to ensure you have correctly implemented Laplace smoothing. For Benoulli Bayes this is, $\\frac{N_{wC} + \\alpha}{N_{C} + |V|\\alpha}$, where $N_{wC}$ is the number of examples with this word in this class, $N_{C}$ is the total number of examples in this class, $V$ is the vocabulary so $|V|$ is the size of the vocabulary, and $\\alpha$ is the smoothing value, for Laplace Smoothing this is $\\alpha = 1$.\n",
        "\n",
        "Your job is to write code that parses the text files and calculates probabilities for each dictionary word given the review polarity:\n",
        "\n",
        "1. Write a function that can generate the feature vector of a single file given a path to that file. As a test you should be able to generate the example above for the file review_polarity/txt_sentoken/pos/cv996_11592.txt\n",
        "   ```python\n",
        "   def get_feature_vector(path):\n",
        "   ```\n",
        "   *HINT: for reading files in all at once using python:*\n",
        "    ```python\n",
        "   f = open(path, \"r\")\n",
        "   contents = f.read()\n",
        "   ```\n",
        "2. Write a function that can generate the conditional probabilities of each word given in each class, given the directory of the data for a class. You must implement Laplace Smoothing for Bernoulli Naive Bayes correctly.\n",
        "   ```python\n",
        "   def word_probabilities(directory):\n",
        "   ```\n",
        "\n",
        "NOTE: os.scandir(directory), filename.is_file(), open(filename.path, \"r\") are useful here!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import zipfile, io\n",
        "\n",
        "# Upload zip file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Extract it (assuming your file is review_polarity.zip)\n",
        "with zipfile.ZipFile(io.BytesIO(uploaded['review_polarity.zip']), 'r') as zip_ref:\n",
        "    zip_ref.extractall()\n",
        "print(\"✅ Folder extracted successfully!\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "6giVBORCXNRN",
        "outputId": "4102a511-db10-4f5a-8e27-078c2a52dc38"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8638db2c-e6a8-4f3a-9fc5-b723f19ee87b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8638db2c-e6a8-4f3a-9fc5-b723f19ee87b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving review_polarity.zip to review_polarity.zip\n",
            "✅ Folder extracted successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezHSK_skVT_j",
        "outputId": "a00a6548-4851-4867-acc4-9fd771874630"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example pos/cv996_11592.txt:  [0 0 0 0 1 0 1 0 0]\n",
            "Negative vocabulary probabilities:  [0.12275449 0.54491018 0.1756487  0.10179641 0.08682635 0.05489022\n",
            " 0.32035928 0.05988024 0.000998  ]\n",
            "[0.03493014 0.28043912 0.05489022 0.0259481  0.15469062 0.09680639\n",
            " 0.48502994 0.13273453 0.000998  ]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# YOUR CODE GOES HERE\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Define the fixed vocabulary (the words we’ll track)\n",
        "VOCAB = [\"awful\", \"bad\", \"boring\", \"dull\", \"effective\",\n",
        "         \"enjoyable\", \"great\", \"hilarious\", \"adoxography\"]\n",
        "\n",
        "# --- 1. Generate the binary feature vector for a single file ---\n",
        "def get_feature_vector(path):\n",
        "    \"\"\"\n",
        "    Returns a binary numpy array of length |VOCAB|,\n",
        "    where each element indicates whether the corresponding\n",
        "    word is present in the text file.\n",
        "    \"\"\"\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        contents = f.read().lower()  # make lowercase for consistency\n",
        "    features = np.zeros(len(VOCAB), dtype=int)\n",
        "\n",
        "    for i, word in enumerate(VOCAB):\n",
        "        if word in contents:\n",
        "            features[i] = 1\n",
        "    return features\n",
        "\n",
        "\n",
        "# --- 2. Compute conditional probabilities for each word given the class ---\n",
        "def word_probabilities(directory, alpha=1):\n",
        "    \"\"\"\n",
        "    Calculates P(word | class) for each word in VOCAB,\n",
        "    using Laplace smoothing for Bernoulli Naive Bayes.\n",
        "    \"\"\"\n",
        "    files = [f for f in os.scandir(directory) if f.is_file()]\n",
        "    N_C = len(files)  # number of examples in this class\n",
        "    N_wC = np.zeros(len(VOCAB))  # count of documents in class containing each word\n",
        "\n",
        "    # Count how many documents contain each word\n",
        "    for file in files:\n",
        "        vec = get_feature_vector(file.path)\n",
        "        N_wC += vec  # add 1 if the word appears in the file\n",
        "\n",
        "    # Apply Laplace smoothing:\n",
        "    # P(word | class) = (N_wC + α) / (N_C + 2α)\n",
        "    # For Bernoulli NB, each word can appear (1) or not (0)\n",
        "    probs = (N_wC + alpha) / (N_C + 2 * alpha)\n",
        "\n",
        "    return probs\n",
        "\n",
        "\n",
        "# Test cases\n",
        "example_vec = get_feature_vector('review_polarity/txt_sentoken/pos/cv996_11592.txt')\n",
        "neg_probs = word_probabilities('review_polarity/txt_sentoken/neg')\n",
        "pos_probs = word_probabilities('review_polarity/txt_sentoken/pos')\n",
        "\n",
        "print(\"Example pos/cv996_11592.txt: \", example_vec)\n",
        "print(\"Negative vocabulary probabilities: \", neg_probs)\n",
        "print(pos_probs)\n",
        "\n",
        "# Expected output - note that numbers may vary depending on how you parse but it should not be by much\n",
        "# [0 0 0 0 1 0 1 0 0]\n",
        "# [0.12190287 0.54112983 0.17443013 0.10109019 0.08622398 0.05450942\n",
        "#  0.31813677 0.05946482 0.00099108]\n",
        "# [0.03468781 0.27849356 0.05450942 0.02576809 0.15361744 0.09613479\n",
        "#  0.48166501 0.13181368 0.00099108]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SazMvB76VT_k"
      },
      "source": [
        "# QUESTION 3 (EXPECTED) - Text classification  - 8 Marks\n",
        "\n",
        "Write Python code for classifying a particular test instance (in our case, a movie review) following a Bernoulli Naive Bayes approach, i.e. you just model the presence/absence of each word. NOTE: because we are not counting word occurences we are simply using a binary presence feature vector (the word appears or does not apepar in a document), we can use the Bernoulli approach. Your code should calculate the likelihood that the review is positive, given the corresponding conditional probabilities for each dictionary word, as well as the likelihood that the review is negative, given the corresponding conditional probabilities for each dictionary word. Check that your code works by providing a few example cases of prediction. Your code should be written from \"scratch\" and only use NumPy but **NOT** machine learning libraries like scikit-learn, tensorflow or pytorch.\n",
        "\n",
        "You should write three functions:\n",
        "\n",
        "1. A function that computes the likelihood given the path to a file and the conditional probabilities for a particular class. In Bernoulli Bayes we care about the exclusion terms, i.e. the likelihood is $ p(\\mathbf{x} | C_k) = \\prod_{i = 0}^{n}  p_{k_i}^{x_i}(1 - p_{k_i})^{1 - x_i}$ where $\\mathbf{x}$ is the feature vector for a particular file, $C_k$ is the class k (for us there are two pos and neg), $n$ is the number of vocabulary items, $p_{k_i}$ is the porbability of the vocabulary word $i$ appearing in class $k$, $x_i$ is the $i'th$ entry in the feature vector $\\mathbf{x}$. Note how $x_i$ is essentialy an indicator function so that the likelihood accounts for the entire vocabulary even if the word is not present. In that case we get the exclusion probability $1 - p_{k_i}$. Bernoulli Bayes is interesting in that way!\n",
        "   ```python\n",
        "   def likelihood(path, probs):\n",
        "   ```\n",
        "2. A function that computes the class priors given two directories, and returns the results as a list [$p(C_1)$, $p(C_2)$]. Yes we are aware this is a nicely balanced datset where the priors are 50/50, however you can not assume that!\n",
        "   ```python\n",
        "   def class_priors(class_dir_1, class_dir_2):\n",
        "   ```\n",
        "3. A function that returns the class prediction as a string 'positive' or 'negative' depending on the bernouli bayes outcome, NOTE: since we only care about argmax, and the denominator is the same for both classes, you can ignore the denominator. That is your predict function should be $\\underset{k \\in \\{1, \\ldots, K\\}}{\\operatorname{argmax}} p(C_k)p(\\mathbf{x} | C_k)$, note for us $k$ is $2$ because we just have a positive and a negative class.\n",
        "   ```python\n",
        "   def predict(path, neg_probs, pos_probs, neg_prior, pos_prior):\n",
        "   ```\n",
        "4. A function that returns the accuracy of the classifier. Note we would normally, at the very least, split the data into training and test sets. However, here I'd like you write a function that takes two directories, classifies all the files and computes the overall accuracy. Accuracy is $\\frac{TP + TN}{TP + TN + FP + FN}$ where $TP, TN, FP, FN$ are true positives, true ngatives, false positives, and false negatives respectively, i.e., correct classiffications over all classifications.\n",
        "   ```python\n",
        "   def accuracy(neg_dir, pos_dir):\n",
        "   ```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lP7ho2aqVT_k",
        "outputId": "847501d3-cd47-45d6-d58d-07a4076c78e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "review_polarity/txt_sentoken/pos/cv996_11592.txt classified as positive\n",
            "review_polarity/txt_sentoken/pos/cv000_29590.txt classified as negative\n",
            "review_polarity/txt_sentoken/neg/cv001_19502.txt classified as positive\n",
            "review_polarity/txt_sentoken/neg/cv000_29416.txt classified as negative\n",
            "Overall Accuracy:  67.05 %\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE GOES HERE\n",
        "\n",
        "# Compute probabilities for both classes\n",
        "neg_probs = word_probabilities('review_polarity/txt_sentoken/neg')\n",
        "pos_probs = word_probabilities('review_polarity/txt_sentoken/pos')\n",
        "\n",
        "# Compute class priors\n",
        "neg_prior, pos_prior = class_priors('review_polarity/txt_sentoken/neg',\n",
        "                                    'review_polarity/txt_sentoken/pos')\n",
        "\n",
        "# --- Likelihood function ---\n",
        "def likelihood(path, probs):\n",
        "    \"\"\"\n",
        "    Computes the likelihood P(x|Ck) for a file given the class word probabilities.\n",
        "    Uses Bernoulli Naive Bayes formula:\n",
        "        P(x|Ck) = ∏ p_i^x_i * (1 - p_i)^(1 - x_i)\n",
        "    \"\"\"\n",
        "    x = get_feature_vector(path)  # binary vector\n",
        "    p = probs                     # P(word|class)\n",
        "\n",
        "    # To avoid underflow, use log probabilities\n",
        "    log_likelihood = np.sum(x * np.log(p) + (1 - x) * np.log(1 - p))\n",
        "    return np.exp(log_likelihood)  # return actual likelihood\n",
        "\n",
        "\n",
        "# --- Class priors function ---\n",
        "def class_priors(class_dir_1, class_dir_2):\n",
        "    \"\"\"\n",
        "    Computes priors P(C1) and P(C2) from the number of documents in each class.\n",
        "    \"\"\"\n",
        "    N1 = len([f for f in os.scandir(class_dir_1) if f.is_file()])\n",
        "    N2 = len([f for f in os.scandir(class_dir_2) if f.is_file()])\n",
        "    total = N1 + N2\n",
        "    return [N1 / total, N2 / total]\n",
        "\n",
        "\n",
        "# --- Pediction function ---\n",
        "def predict(path, neg_probs, pos_probs, neg_prior, pos_prior):\n",
        "    \"\"\"\n",
        "    Classifies a review as 'positive' or 'negative' using Bernoulli Naive Bayes.\n",
        "    We compare:  P(neg)*P(x|neg)  vs  P(pos)*P(x|pos)\n",
        "    \"\"\"\n",
        "    # use log-space to avoid numeric underflow\n",
        "    x = get_feature_vector(path)\n",
        "\n",
        "    log_neg = np.sum(x * np.log(neg_probs) + (1 - x) * np.log(1 - neg_probs)) + np.log(neg_prior)\n",
        "    log_pos = np.sum(x * np.log(pos_probs) + (1 - x) * np.log(1 - pos_probs)) + np.log(pos_prior)\n",
        "\n",
        "    if log_pos > log_neg:\n",
        "        return \"positive\"\n",
        "    else:\n",
        "        return \"negative\"\n",
        "\n",
        "\n",
        "# ---Accuracy function ---\n",
        "def accuracy(neg_dir, pos_dir):\n",
        "    \"\"\"\n",
        "    Classifies all reviews in both directories and computes accuracy.\n",
        "    Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
        "    \"\"\"\n",
        "    neg_probs = word_probabilities(neg_dir)\n",
        "    pos_probs = word_probabilities(pos_dir)\n",
        "    neg_prior, pos_prior = class_priors(neg_dir, pos_dir)\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # Check negative reviews\n",
        "    for f in os.scandir(neg_dir):\n",
        "        if f.is_file():\n",
        "            pred = predict(f.path, neg_probs, pos_probs, neg_prior, pos_prior)\n",
        "            if pred == \"negative\":\n",
        "                correct += 1\n",
        "            total += 1\n",
        "\n",
        "    # Check positive reviews\n",
        "    for f in os.scandir(pos_dir):\n",
        "        if f.is_file():\n",
        "            pred = predict(f.path, neg_probs, pos_probs, neg_prior, pos_prior)\n",
        "            if pred == \"positive\":\n",
        "                correct += 1\n",
        "            total += 1\n",
        "\n",
        "    return correct / total\n",
        "\n",
        "# Some testcases with correct and incorrect classifications\n",
        "path = 'review_polarity/txt_sentoken/pos/cv996_11592.txt'\n",
        "print(path, 'classified as', predict(path, neg_probs, pos_probs, neg_prior, pos_prior))\n",
        "\n",
        "path = 'review_polarity/txt_sentoken/pos/cv000_29590.txt'\n",
        "print(path, 'classified as', predict(path, neg_probs, pos_probs, neg_prior, pos_prior))\n",
        "\n",
        "path = 'review_polarity/txt_sentoken/neg/cv001_19502.txt'\n",
        "print(path, 'classified as', predict(path, neg_probs, pos_probs, neg_prior, pos_prior))\n",
        "\n",
        "path = 'review_polarity/txt_sentoken/neg/cv000_29416.txt'\n",
        "print(path, 'classified as', predict(path, neg_probs, pos_probs, neg_prior, pos_prior))\n",
        "\n",
        "print(\"Overall Accuracy: \", accuracy('review_polarity/txt_sentoken/neg', 'review_polarity/txt_sentoken/pos') * 100., \"%\")\n",
        "\n",
        "# Expected Output\n",
        "# review_polarity/txt_sentoken/pos/cv996_11592.txt classified as positive\n",
        "# review_polarity/txt_sentoken/pos/cv000_29590.txt classified as negative\n",
        "# review_polarity/txt_sentoken/neg/cv001_19502.txt classified as positive\n",
        "# review_polarity/txt_sentoken/neg/cv000_29416.txt classified as negative\n",
        "# Overall Accuracy:  67.05 %"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42ObcEPLVT_k"
      },
      "source": [
        "# Question 4 (Basic)  - Specifying a Bayesian Network - 6 Marks\n",
        "\n",
        "<img src=\"dyspnea.png\">\n",
        "\n",
        "Using the conventions for DBNs used in probability.ipynb (from the AIMA authors) encode the dyspnea network shown above, note we've provided the code for this below. Once you have constructed the Bayesian network display the cpt for the Lung Cancer Node (using the API provided not just showing the numbers).\n",
        "\n",
        "The cell below contains the code that defines BayesNodes and BayesNetworks and the following cell\n",
        "shows an example of defining the Burglary network and performing a query using direct enumeration and rejection sampling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "yviIb1SkVT_l"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def extend(s, var, val):\n",
        "    \"\"\"Copy dict s and extend it by setting var to val; return copy.\"\"\"\n",
        "    return {**s, var: val}\n",
        "\n",
        "def event_values(event, variables):\n",
        "    \"\"\"Return a tuple of the values of variables in event.\n",
        "    >>> event_values ({'A': 10, 'B': 9, 'C': 8}, ['C', 'A'])\n",
        "    (8, 10)\n",
        "    >>> event_values ((1, 2), ['C', 'A'])\n",
        "    (1, 2)\n",
        "    \"\"\"\n",
        "    if isinstance(event, tuple) and len(event) == len(variables):\n",
        "        return event\n",
        "    else:\n",
        "        return tuple([event[var] for var in variables])\n",
        "\n",
        "def probability(p):\n",
        "    \"\"\"Return true with probability p.\"\"\"\n",
        "    return p > random.uniform(0.0, 1.0)\n",
        "\n",
        "class ProbDist:\n",
        "    \"\"\"A discrete probability distribution. You name the random variable\n",
        "    in the constructor, then assign and query probability of values.\n",
        "    >>> P = ProbDist('Flip'); P['H'], P['T'] = 0.25, 0.75; P['H']\n",
        "    0.25\n",
        "    >>> P = ProbDist('X', {'lo': 125, 'med': 375, 'hi': 500})\n",
        "    >>> P['lo'], P['med'], P['hi']\n",
        "    (0.125, 0.375, 0.5)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, var_name='?', freq=None):\n",
        "        \"\"\"If freq is given, it is a dictionary of values - frequency pairs,\n",
        "        then ProbDist is normalized.\"\"\"\n",
        "        self.prob = {}\n",
        "        self.var_name = var_name\n",
        "        self.values = []\n",
        "        if freq:\n",
        "            for (v, p) in freq.items():\n",
        "                self[v] = p\n",
        "            self.normalize()\n",
        "\n",
        "    def __getitem__(self, val):\n",
        "        \"\"\"Given a value, return P(value).\"\"\"\n",
        "        try:\n",
        "            return self.prob[val]\n",
        "        except KeyError:\n",
        "            return 0\n",
        "\n",
        "    def __setitem__(self, val, p):\n",
        "        \"\"\"Set P(val) = p.\"\"\"\n",
        "        if val not in self.values:\n",
        "            self.values.append(val)\n",
        "        self.prob[val] = p\n",
        "\n",
        "    def normalize(self):\n",
        "        \"\"\"Make sure the probabilities of all values sum to 1.\n",
        "        Returns the normalized distribution.\n",
        "        Raises a ZeroDivisionError if the sum of the values is 0.\"\"\"\n",
        "        total = sum(self.prob.values())\n",
        "        if not np.isclose(total, 1.0):\n",
        "            for val in self.prob:\n",
        "                self.prob[val] /= total\n",
        "        return self\n",
        "\n",
        "    def show_approx(self, numfmt='{:.3g}'):\n",
        "        \"\"\"Show the probabilities rounded and sorted by key, for the\n",
        "        sake of portable doctests.\"\"\"\n",
        "        return ', '.join([('{}: ' + numfmt).format(v, p) for (v, p) in sorted(self.prob.items())])\n",
        "\n",
        "    def __repr__(self):\n",
        "        return \"P({})\".format(self.var_name)\n",
        "\n",
        "\n",
        "class BayesNode:\n",
        "    \"\"\"A conditional probability distribution for a boolean variable,\n",
        "    P(X | parents). Part of a BayesNet.\"\"\"\n",
        "\n",
        "    def __init__(self, X, parents, cpt):\n",
        "        \"\"\"X is a variable name, and parents a sequence of variable\n",
        "        names or a space-separated string. cpt, the conditional\n",
        "        probability table, takes one of these forms:\n",
        "\n",
        "        * A number, the unconditional probability P(X=true). You can\n",
        "          use this form when there are no parents.\n",
        "\n",
        "        * A dict {v: p, ...}, the conditional probability distribution\n",
        "          P(X=true | parent=v) = p. When there's just one parent.\n",
        "\n",
        "        * A dict {(v1, v2, ...): p, ...}, the distribution P(X=true |\n",
        "          parent1=v1, parent2=v2, ...) = p. Each key must have as many\n",
        "          values as there are parents. You can use this form always;\n",
        "          the first two are just conveniences.\n",
        "\n",
        "        In all cases the probability of X being false is left implicit,\n",
        "        since it follows from P(X=true).\n",
        "\n",
        "        >>> X = BayesNode('X', '', 0.2)\n",
        "        >>> Y = BayesNode('Y', 'P', {T: 0.2, F: 0.7})\n",
        "        >>> Z = BayesNode('Z', 'P Q',\n",
        "        ...    {(T, T): 0.2, (T, F): 0.3, (F, T): 0.5, (F, F): 0.7})\n",
        "        \"\"\"\n",
        "        if isinstance(parents, str):\n",
        "            parents = parents.split()\n",
        "\n",
        "        # We store the table always in the third form above.\n",
        "        if isinstance(cpt, (float, int)):  # no parents, 0-tuple\n",
        "            cpt = {(): cpt}\n",
        "        elif isinstance(cpt, dict):\n",
        "            # one parent, 1-tuple\n",
        "            if cpt and isinstance(list(cpt.keys())[0], bool):\n",
        "                cpt = {(v,): p for v, p in cpt.items()}\n",
        "\n",
        "        assert isinstance(cpt, dict)\n",
        "        for vs, p in cpt.items():\n",
        "            assert isinstance(vs, tuple) and len(vs) == len(parents)\n",
        "            assert all(isinstance(v, bool) for v in vs)\n",
        "            assert 0 <= p <= 1\n",
        "\n",
        "        self.variable = X\n",
        "        self.parents = parents\n",
        "        self.cpt = cpt\n",
        "        self.children = []\n",
        "\n",
        "    def p(self, value, event):\n",
        "        \"\"\"Return the conditional probability\n",
        "        P(X=value | parents=parent_values), where parent_values\n",
        "        are the values of parents in event. (event must assign each\n",
        "        parent a value.)\n",
        "        >>> bn = BayesNode('X', 'Burglary', {T: 0.2, F: 0.625})\n",
        "        >>> bn.p(False, {'Burglary': False, 'Earthquake': True})\n",
        "        0.375\"\"\"\n",
        "        assert isinstance(value, bool)\n",
        "        ptrue = self.cpt[event_values(event, self.parents)]\n",
        "        return ptrue if value else 1 - ptrue\n",
        "\n",
        "    def sample(self, event):\n",
        "        \"\"\"Sample from the distribution for this variable conditioned\n",
        "        on event's values for parent_variables. That is, return True/False\n",
        "        at random according with the conditional probability given the\n",
        "        parents.\"\"\"\n",
        "        return probability(self.p(True, event))\n",
        "\n",
        "    def __repr__(self):\n",
        "        return repr((self.variable, ' '.join(self.parents)))\n",
        "\n",
        "\n",
        "class BayesNet:\n",
        "    \"\"\"Bayesian network containing only boolean-variable nodes.\"\"\"\n",
        "\n",
        "    def __init__(self, node_specs=None):\n",
        "        \"\"\"Nodes must be ordered with parents before children.\"\"\"\n",
        "        self.nodes = []\n",
        "        self.variables = []\n",
        "        node_specs = node_specs or []\n",
        "        for node_spec in node_specs:\n",
        "            self.add(node_spec)\n",
        "\n",
        "    def add(self, node_spec):\n",
        "        \"\"\"Add a node to the net. Its parents must already be in the\n",
        "        net, and its variable must not.\"\"\"\n",
        "        node = BayesNode(*node_spec)\n",
        "        assert node.variable not in self.variables\n",
        "        assert all((parent in self.variables) for parent in node.parents)\n",
        "        self.nodes.append(node)\n",
        "        self.variables.append(node.variable)\n",
        "        for parent in node.parents:\n",
        "            self.variable_node(parent).children.append(node)\n",
        "\n",
        "    def variable_node(self, var):\n",
        "        \"\"\"Return the node for the variable named var.\n",
        "        >>> burglary.variable_node('Burglary').variable\n",
        "        'Burglary'\"\"\"\n",
        "        for n in self.nodes:\n",
        "            if n.variable == var:\n",
        "                return n\n",
        "        raise Exception(\"No such variable: {}\".format(var))\n",
        "\n",
        "    def variable_values(self, var):\n",
        "        \"\"\"Return the domain of var.\"\"\"\n",
        "        return [True, False]\n",
        "\n",
        "    def __repr__(self):\n",
        "        return 'BayesNet({0!r})'.format(self.nodes)\n",
        "\n",
        "\n",
        "def enumerate_all(variables, e, bn):\n",
        "    \"\"\"Return the sum of those entries in P(variables | e{others})\n",
        "    consistent with e, where P is the joint distribution represented\n",
        "    by bn, and e{others} means e restricted to bn's other variables\n",
        "    (the ones other than variables). Parents must precede children in variables.\"\"\"\n",
        "    if not variables:\n",
        "        return 1.0\n",
        "    Y, rest = variables[0], variables[1:]\n",
        "    Ynode = bn.variable_node(Y)\n",
        "    if Y in e:\n",
        "        return Ynode.p(e[Y], e) * enumerate_all(rest, e, bn)\n",
        "    else:\n",
        "        return sum(Ynode.p(y, e) * enumerate_all(rest, extend(e, Y, y), bn)\n",
        "                   for y in bn.variable_values(Y))\n",
        "\n",
        "def enumeration_ask(X, e, bn):\n",
        "    \"\"\"\n",
        "    [Figure 14.9]\n",
        "    Return the conditional probability distribution of variable X\n",
        "    given evidence e, from BayesNet bn.\n",
        "    >>> enumeration_ask('Burglary', dict(JohnCalls=T, MaryCalls=T), burglary\n",
        "    ...  ).show_approx()\n",
        "    'False: 0.716, True: 0.284'\"\"\"\n",
        "    assert X not in e, \"Query variable must be distinct from evidence\"\n",
        "    Q = ProbDist(X)\n",
        "    for xi in bn.variable_values(X):\n",
        "        Q[xi] = enumerate_all(bn.variables, extend(e, X, xi), bn)\n",
        "    return Q.normalize()\n",
        "\n",
        "def consistent_with(event, evidence):\n",
        "    \"\"\"Is event consistent with the given evidence?\"\"\"\n",
        "    return all(evidence.get(k, v) == v for k, v in event.items())\n",
        "\n",
        "def prior_sample(bn):\n",
        "    \"\"\"\n",
        "    [Figure 14.13]\n",
        "    Randomly sample from bn's full joint distribution.\n",
        "    The result is a {variable: value} dict.\n",
        "    \"\"\"\n",
        "    event = {}\n",
        "    for node in bn.nodes:\n",
        "        event[node.variable] = node.sample(event)\n",
        "    return event\n",
        "\n",
        "def rejection_sampling(X, e, bn, N=10000):\n",
        "    \"\"\"\n",
        "    [Figure 14.14]\n",
        "    Estimate the probability distribution of variable X given\n",
        "    evidence e in BayesNet bn, using N samples.\n",
        "    Raises a ZeroDivisionError if all the N samples are rejected,\n",
        "    i.e., inconsistent with e.\n",
        "    >>> random.seed(47)\n",
        "    >>> rejection_sampling('Burglary', dict(JohnCalls=T, MaryCalls=T),\n",
        "    ...   burglary, 10000).show_approx()\n",
        "    'False: 0.7, True: 0.3'\n",
        "    \"\"\"\n",
        "    counts = {x: 0 for x in bn.variable_values(X)}  # bold N in [Figure 14.14]\n",
        "    for j in range(N):\n",
        "        sample = prior_sample(bn)  # boldface x in [Figure 14.14]\n",
        "        if consistent_with(sample, e):\n",
        "            counts[sample[X]] += 1\n",
        "    return ProbDist(X, counts)\n",
        "\n",
        "def weighted_sample(bn, e):\n",
        "    \"\"\"\n",
        "    Sample an event from bn that's consistent with the evidence e;\n",
        "    return the event and its weight, the likelihood that the event\n",
        "    accords to the evidence.\n",
        "    \"\"\"\n",
        "    w = 1\n",
        "    event = dict(e)  # boldface x in [Figure 14.15]\n",
        "    for node in bn.nodes:\n",
        "        Xi = node.variable\n",
        "        if Xi in e:\n",
        "            w *= node.p(e[Xi], event)\n",
        "        else:\n",
        "            event[Xi] = node.sample(event)\n",
        "    return event, w\n",
        "\n",
        "def likelihood_weighting(X, e, bn, N=10000):\n",
        "    \"\"\"\n",
        "    [Figure 14.15]\n",
        "    Estimate the probability distribution of variable X given\n",
        "    evidence e in BayesNet bn.\n",
        "    >>> random.seed(1017)\n",
        "    >>> likelihood_weighting('Burglary', dict(JohnCalls=T, MaryCalls=T),\n",
        "    ...   burglary, 10000).show_approx()\n",
        "    'False: 0.702, True: 0.298'\n",
        "    \"\"\"\n",
        "    W = {x: 0 for x in bn.variable_values(X)}\n",
        "    for j in range(N):\n",
        "        sample, weight = weighted_sample(bn, e)  # boldface x, w in [Figure 14.15]\n",
        "        W[sample[X]] += weight\n",
        "    return ProbDist(X, W)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJLI5xkUVT_m",
        "outputId": "53489f15-c036-4ec8-ee1e-2444cd43eb11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({False: 7957, True: 2043})\n"
          ]
        }
      ],
      "source": [
        "# Example of some sampling of a Bayes Node\n",
        "\n",
        "from collections import Counter\n",
        "bn = BayesNode('X', 'Burglary', {True: 0.2, False: 0.625})\n",
        "\n",
        "bn.p(True, {'Burglary': False, 'Earthquake': True})\n",
        "\n",
        "samples = []\n",
        "for i in range(0,10000):\n",
        "    samples.append(bn.sample({'Burglary': True, 'Earthquake': True}))\n",
        "print(Counter(samples))\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SP5oXOzNVT_m",
        "outputId": "20a9b068-f188-4d01-99f3-5e0cf5d94422"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{(True, True): 0.95, (True, False): 0.94, (False, True): 0.29, (False, False): 0.001}\n",
            "0.2841718353643929 0.7158281646356071\n",
            "False: 0.833, True: 0.167\n"
          ]
        }
      ],
      "source": [
        "# Example of a BayesNet and some queries\n",
        "\n",
        "burglary = BayesNet([\n",
        "        ('Burglary', '', 0.001),\n",
        "        ('Earthquake', '', 0.002),\n",
        "        ('Alarm', ['Burglary', 'Earthquake'],\n",
        "         {(True, True): 0.95, (True, False): 0.94, (False, True): 0.29, (False, False): 0.001}),\n",
        "        ('JohnCalls', 'Alarm', {True: 0.90, False: 0.05}),\n",
        "        ('MaryCalls', 'Alarm', {True: 0.70, False: 0.01})\n",
        "    ])\n",
        "print(burglary.variable_node('Alarm').cpt)\n",
        "ans_dist = enumeration_ask('Burglary', {'JohnCalls': True, 'MaryCalls': True}, burglary)\n",
        "print(ans_dist[True],ans_dist[False])\n",
        "print(rejection_sampling('Burglary', dict(JohnCalls=True, MaryCalls=True), burglary, 10000).show_approx())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0Wsvsg3VT_m",
        "outputId": "052fb465-4985-4a38-8920-4704380b7534"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{(True,): 0.1, (False,): 0.01}\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE GOES HERE\n",
        "# Name your Bayes network for Dispnea  and specify it below\n",
        "\n",
        "dyspnea = BayesNet([\n",
        "    ('VisitToAsia', '', 0.01),  # P(Asia=True)\n",
        "    ('Smoking', '', 0.5),       # P(Smoking=True)\n",
        "\n",
        "    ('Tuberculosis', 'VisitToAsia', {True: 0.05, False: 0.01}),\n",
        "    ('LungCancer', 'Smoking', {True: 0.10, False: 0.01}),\n",
        "\n",
        "    ('Either', ['Tuberculosis', 'LungCancer'],\n",
        "        {(True, True): 1.0, (True, False): 1.0, (False, True): 1.0, (False, False): 0.0}),\n",
        "\n",
        "    ('XRay', 'Either', {True: 0.98, False: 0.05}),\n",
        "    ('Dyspnea', 'Either', {True: 0.90, False: 0.30})\n",
        "])\n",
        "\n",
        "# Display the CPT for the LungCancer node\n",
        "print(dyspnea.variable_node('LungCancer').cpt)\n",
        "\n",
        "\n",
        "# Expected output\n",
        "# {(True,): 0.1, (False,): 0.01}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9x_KWgiVT_n"
      },
      "source": [
        "# Question 5 (Expected) - Querying the Bayesian Network - 6 Marks\n",
        "\n",
        "Answer the following queries using exact inference with enumeration and approximate inference of the same queries using both rejection sampling and likelihood weighting:\n",
        "\n",
        "1. given that a patient has tuberculosis, what is the likelihood of being a smoker?\n",
        "2. given that a patient has been in Asia and has a positive x-ray, what is the likelihood of having dyspnea?\n",
        "3. given that a patient is a smoker and has lung cancer, what is the likelihood of having dyspnea?\n",
        "\n",
        "Use 100000 samples where needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rQitIBLVT_n",
        "outputId": "546a7aca-6816-409b-c4f5-16aeaa2d7514"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Likelihood of Smoker given Tuberculosis using exact inference:  0.5\n",
            "Likelihood of Smoker given Tuberculosis using approximate rejection sampling:  0.5070993914807302\n",
            "Likelihood of Smoker given Tuberculosis using approximate likelihood weighting:  0.4979386607074076\n",
            "Likelihood of Dyspnea given VisitToAsia and Positive XRay using exact inference:  0.7143770353395248\n",
            "Likelihood of Dyspnea given VisitToAsia and Positive XRay using approximate rejection sampling:  0.6643835616438356\n",
            "Likelihood of Dyspnea given VisitToAsia and Positive XRay using approximate likelihood weighting:  0.7098027061453499\n",
            "Likelihood of Dyspnea given LungCancer and Smoker using exact inference:  0.9\n",
            "Likelihood of Dyspnea given LungCancer and Smoker using approximate rejection sampling:  0.9016590045972417\n",
            "Likelihood of Dyspnea given LungCancer and Smoker using approximate likelihood weighting:  0.9003500000001374\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE GOES HERE\n",
        "\n",
        "\n",
        "# Query 1: Likelihood of Smoker given Tuberculosis\n",
        "exact_1 = enumeration_ask('Smoking', {'Tuberculosis': True}, dyspnea)\n",
        "reject_1 = rejection_sampling('Smoking', {'Tuberculosis': True}, dyspnea, 100000)\n",
        "weight_1 = likelihood_weighting('Smoking', {'Tuberculosis': True}, dyspnea, 100000)\n",
        "\n",
        "print(\"Likelihood of Smoker given Tuberculosis using exact inference: \", exact_1[True])\n",
        "print(\"Likelihood of Smoker given Tuberculosis using approximate rejection sampling: \", reject_1[True])\n",
        "print(\"Likelihood of Smoker given Tuberculosis using approximate likelihood weighting: \", weight_1[True])\n",
        "\n",
        "\n",
        "# Query 2: Likelihood of Dyspnea given VisitToAsia and Positive XRay\n",
        "exact_2 = enumeration_ask('Dyspnea', {'VisitToAsia': True, 'XRay': True}, dyspnea)\n",
        "reject_2 = rejection_sampling('Dyspnea', {'VisitToAsia': True, 'XRay': True}, dyspnea, 100000)\n",
        "weight_2 = likelihood_weighting('Dyspnea', {'VisitToAsia': True, 'XRay': True}, dyspnea, 100000)\n",
        "\n",
        "print(\"Likelihood of Dyspnea given VisitToAsia and Positive XRay using exact inference: \", exact_2[True])\n",
        "print(\"Likelihood of Dyspnea given VisitToAsia and Positive XRay using approximate rejection sampling: \", reject_2[True])\n",
        "print(\"Likelihood of Dyspnea given VisitToAsia and Positive XRay using approximate likelihood weighting: \", weight_2[True])\n",
        "\n",
        "\n",
        "# Query 3: Likelihood of Dyspnea given LungCancer and Smoker\n",
        "exact_3 = enumeration_ask('Dyspnea', {'LungCancer': True, 'Smoking': True}, dyspnea)\n",
        "reject_3 = rejection_sampling('Dyspnea', {'LungCancer': True, 'Smoking': True}, dyspnea, 100000)\n",
        "weight_3 = likelihood_weighting('Dyspnea', {'LungCancer': True, 'Smoking': True}, dyspnea, 100000)\n",
        "\n",
        "print(\"Likelihood of Dyspnea given LungCancer and Smoker using exact inference: \", exact_3[True])\n",
        "print(\"Likelihood of Dyspnea given LungCancer and Smoker using approximate rejection sampling: \", reject_3[True])\n",
        "print(\"Likelihood of Dyspnea given LungCancer and Smoker using approximate likelihood weighting: \", weight_3[True])\n",
        "\n",
        "\n",
        "# Expected output - note the sampling methods should return similar but not exact numbers\n",
        "# Likelihood of Smoker given Tuberculosis using exact inference:  0.5\n",
        "# Likelihood of Smoker given Tuberculosis using approximate rejection sampling:  0.4874274661508704\n",
        "# Likelihood of Smoker given Tuberculosis using approximate likelihood weighting:  0.49887711620407665\n",
        "# Likelihood of Dispnea given VisitToAsia and PositiveXRay using exact inference:  0.6811011940658546\n",
        "# Likelihood of Dispnea given VisitToAsia and PositiveXRay using approximate rejection sampling:  0.727810650887574\n",
        "# Likelihood of Dispnea given VisitToAsia and PositiveXRay using approximate likelihood weighting:  0.6789105866434472\n",
        "# Likelihood of Dispnea given LungCancer and Smoker using exact inference:  0.8200000000000001\n",
        "# Likelihood of Dispnea given LungCancer and Smoker using approximate rejection sampling:  0.8162444712505026\n",
        "# Likelihood of Dispnea given LungCancer and Smoker using approximate likelihood weighting:  0.8185400000002676\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}